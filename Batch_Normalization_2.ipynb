{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 11s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Loading the inbuilt dataset 'MNIST' from keras\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the image data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "validation_images = train_images[:5000]\n",
    "validation_labels = train_labels[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the NN architecture\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [28, 28]),\n",
    "    keras.layers.Dense(300, use_bias = False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(keras.activations.relu),\n",
    "    keras.layers.Dense(200, use_bias = False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(keras.activations.relu),\n",
    "    keras.layers.Dense(100, use_bias = False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(keras.activations.relu),\n",
    "    keras.layers.Dense(10, activation = keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               60000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 318,610\n",
      "Trainable params: 317,410\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Printing the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'batch_normalization/gamma:0' shape=(300,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization/beta:0' shape=(300,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization/moving_mean:0' shape=(300,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization/moving_variance:0' shape=(300,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the layer at index 2 to get infomation about the variables.\n",
    "model.layers[2].variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization/gamma:0\n",
      "batch_normalization/beta:0\n",
      "batch_normalization/moving_mean:0\n",
      "batch_normalization/moving_variance:0\n"
     ]
    }
   ],
   "source": [
    "# Printing the variable\n",
    "for variable in model.layers[2].variables:\n",
    "    print(variable.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "sgd = keras.optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9,nesterov = True)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.4629 - accuracy: 0.8341 - val_loss: 0.3405 - val_accuracy: 0.8754\n",
      "Epoch 2/60\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3492 - accuracy: 0.8713 - val_loss: 0.2742 - val_accuracy: 0.8960\n",
      "Epoch 3/60\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3087 - accuracy: 0.8850 - val_loss: 0.2904 - val_accuracy: 0.8846\n",
      "Epoch 4/60\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2831 - accuracy: 0.8953 - val_loss: 0.2294 - val_accuracy: 0.9100\n",
      "Epoch 5/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2636 - accuracy: 0.9016 - val_loss: 0.2527 - val_accuracy: 0.9036\n",
      "Epoch 6/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2471 - accuracy: 0.9074 - val_loss: 0.2046 - val_accuracy: 0.9226\n",
      "Epoch 7/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2351 - accuracy: 0.9112 - val_loss: 0.1888 - val_accuracy: 0.9260\n",
      "Epoch 8/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2220 - accuracy: 0.9165 - val_loss: 0.1891 - val_accuracy: 0.9258\n",
      "Epoch 9/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2106 - accuracy: 0.9202 - val_loss: 0.1789 - val_accuracy: 0.9300\n",
      "Epoch 10/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1987 - accuracy: 0.9247 - val_loss: 0.1992 - val_accuracy: 0.9270\n",
      "Epoch 11/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1935 - accuracy: 0.9256 - val_loss: 0.1849 - val_accuracy: 0.9254\n",
      "Epoch 12/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1823 - accuracy: 0.9310 - val_loss: 0.1423 - val_accuracy: 0.9432\n",
      "Epoch 13/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1736 - accuracy: 0.9346 - val_loss: 0.1419 - val_accuracy: 0.9434\n",
      "Epoch 14/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1664 - accuracy: 0.9367 - val_loss: 0.1397 - val_accuracy: 0.9472\n",
      "Epoch 15/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1613 - accuracy: 0.9385 - val_loss: 0.1507 - val_accuracy: 0.9426\n",
      "Epoch 16/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1543 - accuracy: 0.9421 - val_loss: 0.1428 - val_accuracy: 0.9446\n",
      "Epoch 17/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1499 - accuracy: 0.9422 - val_loss: 0.1176 - val_accuracy: 0.9550\n",
      "Epoch 18/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1430 - accuracy: 0.9450 - val_loss: 0.1076 - val_accuracy: 0.9612\n",
      "Epoch 19/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1371 - accuracy: 0.9475 - val_loss: 0.0956 - val_accuracy: 0.9608\n",
      "Epoch 20/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1301 - accuracy: 0.9501 - val_loss: 0.1034 - val_accuracy: 0.9596\n",
      "Epoch 21/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1272 - accuracy: 0.9513 - val_loss: 0.0977 - val_accuracy: 0.9616\n",
      "Epoch 22/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1229 - accuracy: 0.9537 - val_loss: 0.1187 - val_accuracy: 0.9528\n",
      "Epoch 23/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1180 - accuracy: 0.9542 - val_loss: 0.1049 - val_accuracy: 0.9562\n",
      "Epoch 24/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1155 - accuracy: 0.9563 - val_loss: 0.0907 - val_accuracy: 0.9674\n",
      "Epoch 25/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1090 - accuracy: 0.9578 - val_loss: 0.0724 - val_accuracy: 0.9752\n",
      "Epoch 26/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1055 - accuracy: 0.9599 - val_loss: 0.0819 - val_accuracy: 0.9692\n",
      "Epoch 27/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1037 - accuracy: 0.9606 - val_loss: 0.0706 - val_accuracy: 0.9758\n",
      "Epoch 28/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0992 - accuracy: 0.9627 - val_loss: 0.0631 - val_accuracy: 0.9752\n",
      "Epoch 29/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0942 - accuracy: 0.9646 - val_loss: 0.0613 - val_accuracy: 0.9792\n",
      "Epoch 30/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0914 - accuracy: 0.9655 - val_loss: 0.0716 - val_accuracy: 0.9746\n",
      "Epoch 31/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0901 - accuracy: 0.9662 - val_loss: 0.0674 - val_accuracy: 0.9732\n",
      "Epoch 32/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0843 - accuracy: 0.9677 - val_loss: 0.0781 - val_accuracy: 0.9720\n",
      "Epoch 33/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0843 - accuracy: 0.9685 - val_loss: 0.0671 - val_accuracy: 0.9774\n",
      "Epoch 34/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0811 - accuracy: 0.9698 - val_loss: 0.0885 - val_accuracy: 0.9670\n",
      "Epoch 35/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0823 - accuracy: 0.9689 - val_loss: 0.0810 - val_accuracy: 0.9668\n",
      "Epoch 36/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0745 - accuracy: 0.9722 - val_loss: 0.0797 - val_accuracy: 0.9704\n",
      "Epoch 37/60\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0754 - accuracy: 0.9717 - val_loss: 0.0608 - val_accuracy: 0.9756\n",
      "Epoch 38/60\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0717 - accuracy: 0.9728 - val_loss: 0.0440 - val_accuracy: 0.9824\n",
      "Epoch 39/60\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0719 - accuracy: 0.9729 - val_loss: 0.0539 - val_accuracy: 0.9798\n",
      "Epoch 40/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0690 - accuracy: 0.9737 - val_loss: 0.0553 - val_accuracy: 0.9790\n",
      "Epoch 41/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0658 - accuracy: 0.9753 - val_loss: 0.0601 - val_accuracy: 0.9776\n",
      "Epoch 42/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0638 - accuracy: 0.9758 - val_loss: 0.0725 - val_accuracy: 0.9720\n",
      "Epoch 43/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0638 - accuracy: 0.9761 - val_loss: 0.0329 - val_accuracy: 0.9884\n",
      "Epoch 44/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0599 - accuracy: 0.9777 - val_loss: 0.0725 - val_accuracy: 0.9756\n",
      "Epoch 45/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0606 - accuracy: 0.9769 - val_loss: 0.0443 - val_accuracy: 0.9854\n",
      "Epoch 46/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0566 - accuracy: 0.9783 - val_loss: 0.0381 - val_accuracy: 0.9850\n",
      "Epoch 47/60\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0564 - accuracy: 0.9788 - val_loss: 0.0681 - val_accuracy: 0.9768\n",
      "Epoch 48/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0574 - accuracy: 0.9783 - val_loss: 0.0485 - val_accuracy: 0.9792\n",
      "Epoch 49/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0562 - accuracy: 0.9786 - val_loss: 0.0365 - val_accuracy: 0.9860\n",
      "Epoch 50/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0527 - accuracy: 0.9800 - val_loss: 0.0319 - val_accuracy: 0.9896\n",
      "Epoch 51/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0503 - accuracy: 0.9814 - val_loss: 0.0315 - val_accuracy: 0.9900\n",
      "Epoch 52/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0497 - accuracy: 0.9816 - val_loss: 0.0354 - val_accuracy: 0.9868\n",
      "Epoch 53/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0494 - accuracy: 0.9814 - val_loss: 0.0729 - val_accuracy: 0.9760\n",
      "Epoch 54/60\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0440 - accuracy: 0.9834 - val_loss: 0.0257 - val_accuracy: 0.9920\n",
      "Epoch 55/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0456 - accuracy: 0.9829 - val_loss: 0.0435 - val_accuracy: 0.9806\n",
      "Epoch 56/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0449 - accuracy: 0.9830 - val_loss: 0.0283 - val_accuracy: 0.9902\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0418 - accuracy: 0.9847 - val_loss: 0.0250 - val_accuracy: 0.9908\n",
      "Epoch 58/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 0.0328 - val_accuracy: 0.9866\n",
      "Epoch 59/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 0.0434 - val_accuracy: 0.9858\n",
      "Epoch 60/60\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0449 - accuracy: 0.9835 - val_loss: 0.0260 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168ab2700>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(train_images, train_labels, epochs = 60, \n",
    "          validation_data = (validation_images, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5406 - accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5406075119972229, 0.8945000171661377]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
